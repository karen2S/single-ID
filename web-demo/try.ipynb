{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58af92c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import json\n",
    "import sys\n",
    "from pyjarowinkler import distance\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdffb6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = {\n",
    "    'cleaned_name': 'EDY PRIYONO S',\n",
    "    'cleaned_TEMPAT_LAHIR': 'SEMARANG',\n",
    "    'TGL_LAHIR': date(1967, 10, 1),  # assumed placeholder; change if needed\n",
    "    'cleaned_no_ktp': None,\n",
    "    'cleaned_no_npwp': '5847834155340254',\n",
    "    'cleaned_alamat': 'SODONG 5',\n",
    "    'cleaned_NAMA_IBU_KANDUNG': 'DIFFERENT MOTHER',\n",
    "    'CD_SP': '100103',\n",
    "    'cleaned_name_cob': None,\n",
    "    'cleaned_no_ktp_cob': None,\n",
    "    'TGL_LAHIR_COBORR': None,\n",
    "    'cleaned_alamat_cob': None\n",
    "}\n",
    "df_test = pd.DataFrame([sample_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0322bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",  \n",
    "    database=\"skripsi\" \n",
    ")\n",
    "\n",
    "cursor = conn.cursor(dictionary=True)\n",
    "\n",
    "# Fetch data from bigram_index\n",
    "cursor.execute(\"SELECT * FROM bigram_index\")\n",
    "\n",
    "bigram_groups = cursor.fetchall()\n",
    "\n",
    "bigram_dict = {\n",
    "    row['bigram']: json.loads(row['group_values'])\n",
    "    for row in bigram_groups\n",
    "}\n",
    "\n",
    "# Fetch data from bigram_index\n",
    "cursor.execute(\"SELECT * FROM monre_dict\")\n",
    "monre_groups = cursor.fetchall()\n",
    "monre_dict = {\n",
    "    row['cleaned_name']: json.loads(row['place_index'])\n",
    "    for row in monre_groups\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5abe7042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams(name):\n",
    "    # if not isinstance(name, str):  # Check if 'name' is a string\n",
    "    #     print(f\"Non-string value encountered: {name}\")\n",
    "    name = name.replace(\" \", \"\")  # Remove spaces to consider all characters together\n",
    "    return {name[i: i + 2] for i in range(len(name) - 1)}\n",
    "\n",
    "# Function to compare two names based on bigrams and Jaro-Winkler similarity\n",
    "def compare_bigrams_and_jaro_winkler(name1, name2, threshold=0.5):\n",
    "    bigrams1 = get_bigrams(name1) # Use precomputed bigrams\n",
    "    bigrams2 = get_bigrams(name2)  # Use precomputed bigrams\n",
    "    \n",
    "    # Find the common bigrams between the two names using set intersection\n",
    "    common_bigrams = bigrams1.intersection(bigrams2)\n",
    "    \n",
    "    # Count how many common bigrams there are\n",
    "    common_count = len(common_bigrams)\n",
    "    \n",
    "    # Find the smallest bigram length between the two names\n",
    "    min_bigrams_len = min(len(bigrams1), len(bigrams2))\n",
    "    \n",
    "    # If common bigrams are greater than 50% of the smallest bigram set, calculate Jaro-Winkler\n",
    "    if common_count > threshold * min_bigrams_len:\n",
    "        jaro_winkler_similarity = distance.get_jaro_distance(name1, name2)\n",
    "        return jaro_winkler_similarity\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to calculate Jaro-Winkler distances for names based on selected bigrams\n",
    "def calculate_jaro_winkler_distances(name):\n",
    "    bigrams = get_bigrams(name) # Use precomputed bigrams\n",
    "    bigram_weights = [\n",
    "        (bigram, len(bigram_dict[bigram]))\n",
    "        for bigram in bigrams\n",
    "        if bigram in bigram_dict\n",
    "    ]\n",
    "    \n",
    "    # Sort bigrams by their frequency (lower frequency = higher weight)\n",
    "    bigram_weights_sorted = sorted(bigram_weights, key=lambda x: x[1])\n",
    "\n",
    "    # Select the top 3 least frequent bigrams\n",
    "    selected_bigrams = [bg[0] for bg in bigram_weights_sorted[:5]]\n",
    "    print(selected_bigrams)\n",
    "    \n",
    "    # Find all unique names in the groups of these 3 bigrams\n",
    "    matching_names = set()\n",
    "    for bigram in selected_bigrams:\n",
    "        matching_names.update(bigram_dict[bigram])\n",
    "\n",
    "    matching_names.discard(name)  # Remove the original name from comparison\n",
    "    \n",
    "    # Compute Jaro-Winkler similarity for each name in the matching group using bigram comparison\n",
    "    distances = {}\n",
    "    \n",
    "    for other_name in matching_names:\n",
    "        # Use the new comparison function to check bigram overlap and compute Jaro-Winkler\n",
    "        similarity = compare_bigrams_and_jaro_winkler(name, other_name)\n",
    "        if similarity and similarity > 0.75:\n",
    "            distances[other_name] = similarity\n",
    "\n",
    "    return name, distances  # Return the name and its distances\n",
    "\n",
    "def add_new_name_to_results_dict(new_name):\n",
    "    # Calculate Jaro-Winkler distances for the new name\n",
    "    name, distances = calculate_jaro_winkler_distances(new_name)\n",
    "    \n",
    "    # If the new name has similar names, add it to results_list\n",
    "    if distances:\n",
    "        similar_names_df = pd.DataFrame(\n",
    "            list(distances.items()), columns=[\"similar_name\", \"similarity\"]\n",
    "        )\n",
    "        results_list = similar_names_df[\"similar_name\"].tolist()  # Convert similar names to a list\n",
    "    else:\n",
    "        results_list = []\n",
    "    results_list.append(new_name)\n",
    "    return results_list\n",
    "\n",
    "def jaro_winkler_match(value1, value2, threshold=0.92): # Default Threshold\n",
    "    if pd.notna(value1) and pd.notna(value2):\n",
    "        value1_str = str(value1).strip() \n",
    "        value2_str = str(value2).strip() \n",
    "        \n",
    "        # Ensure neither value is an empty string\n",
    "        if value1_str and value2_str:\n",
    "            similarity = distance.get_jaro_distance(value1_str, value2_str)\n",
    "            return similarity >= threshold\n",
    "    return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b95357fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ON', 'IY', 'ED', 'DY', 'NO']\n",
      "   id            NO_AGGR  NAME_GOLIVE flag_PC NAMA_IBU_KANDUNG SEX  \\\n",
      "0   1  12737446259973579  EDY PRIYONO       P          SUDARMI   M   \n",
      "\n",
      "    TGL_LAHIR TEMPAT_LAHIR DT_GOLIVE_VALID   CD_SP  ... cleaned_TEMPAT_LAHIR  \\\n",
      "0  1967-10-01     SEMARANG      2025-06-06  600701  ...             SEMARANG   \n",
      "\n",
      "  cleaned_name    cleaned_no_ktp cleaned_no_npwp cleaned_alamat  \\\n",
      "0  EDY PRIYONO  3374140110670015                         SODONG   \n",
      "\n",
      "  cleaned_name_cob cleaned_no_ktp_cob cleaned_alamat_cob            SID  \\\n",
      "0                                                         6007010000001   \n",
      "\n",
      "  SID_COBORR  \n",
      "0       None  \n",
      "\n",
      "[1 rows x 29 columns]\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "6007010000001\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_test.iterrows():\n",
    "    if not monre_dict:\n",
    "        kode_cabang = row['CD_SP']\n",
    "        \n",
    "        cursor.execute(f\"SELECT COUNT FROM sp_count WHERE CD_SP = ({kode_cabang})\")\n",
    "        last_sequence = cursor.fetchone()\n",
    "        \n",
    "        sid_value = f\"{kode_cabang}{(int(last_sequence['COUNT']) + 1):07d}\"\n",
    "        break\n",
    "    \n",
    "    row_compared = row\n",
    "    matched_dfs = []\n",
    "    results_list = add_new_name_to_results_dict(row['cleaned_name'])\n",
    "    all_indices = set()\n",
    "    for name in results_list:\n",
    "        if name in monre_dict:\n",
    "            indices = monre_dict[name]\n",
    "            all_indices.update(map(int, monre_dict[name]))\n",
    "            id_list = ','.join(map(str, all_indices))\n",
    "            cursor.execute(f\"SELECT * FROM credit_cust WHERE id IN ({id_list})\")\n",
    "            matched_dfs = cursor.fetchall()\n",
    "            matched_dfs = pd.DataFrame(matched_dfs)\n",
    "    \n",
    "    if len(matched_dfs) == 0:\n",
    "        kode_cabang = row['CD_SP']\n",
    "        cursor.execute(f\"SELECT COUNT FROM sp_count WHERE CD_SP = ({kode_cabang})\")\n",
    "        last_sequence = cursor.fetchone()\n",
    "        \n",
    "        sid_value = f\"{kode_cabang}{(int(last_sequence['COUNT']) + 1):07d}\"\n",
    "        break\n",
    "    else:\n",
    "        result_df_nodup = matched_dfs.drop_duplicates(subset='NO_AGGR').reset_index(drop=True)\n",
    "        \n",
    "    name_compared = row['cleaned_name']\n",
    "    dob_compared = row['TGL_LAHIR']\n",
    "    tempat_compared = row['cleaned_TEMPAT_LAHIR']\n",
    "    ktp_kitas_compared = row['cleaned_no_ktp']\n",
    "    mother_name_compared = row['cleaned_NAMA_IBU_KANDUNG'] \n",
    "    npwp_compared = row['cleaned_no_npwp']\n",
    "    address_compared = row['cleaned_alamat']\n",
    "    \n",
    "    print(result_df_nodup)\n",
    "\n",
    "    # Filter result_df based on matching criteria\n",
    "    filtered_result_df = result_df_nodup[\n",
    "        ((pd.notna(result_df_nodup['TGL_LAHIR']) & pd.notna(dob_compared) & \n",
    "        (result_df_nodup['TGL_LAHIR'] == dob_compared)) |\n",
    "        (pd.notna(result_df_nodup['cleaned_no_ktp']) & pd.notna(ktp_kitas_compared) & \n",
    "        (result_df_nodup['cleaned_no_ktp'] == ktp_kitas_compared)) |\n",
    "        (pd.notna(result_df_nodup['cleaned_NAMA_IBU_KANDUNG']) & pd.notna(mother_name_compared) & \n",
    "        (result_df_nodup['cleaned_NAMA_IBU_KANDUNG'] == mother_name_compared)) |\n",
    "        (pd.notna(result_df_nodup['cleaned_no_npwp']) & pd.notna(npwp_compared) & \n",
    "        (result_df_nodup['cleaned_no_npwp'] == npwp_compared))\n",
    "    )]\n",
    "    filtered_result_df = filtered_result_df.copy()\n",
    "    filtered_result_df['flag_SID'] = 'N'  \n",
    "    filtered_result_df['rule_num'] = None\n",
    "\n",
    "    for index, row in filtered_result_df.iterrows():\n",
    "        name_sim = jaro_winkler_match(row['cleaned_name'], name_compared)\n",
    "        print( jaro_winkler_match(row['cleaned_name'], name_compared, threshold=0.95))\n",
    "        print(pd.notna(row['cleaned_alamat']) and jaro_winkler_match(row['cleaned_alamat'], address_compared))\n",
    "        print(pd.notna(row['TGL_LAHIR']) and row['TGL_LAHIR'] == dob_compared)\n",
    "        print(pd.notna(row['cleaned_TEMPAT_LAHIR']) and row['cleaned_TEMPAT_LAHIR'] == tempat_compared)\n",
    "        if (\n",
    "            name_sim and \n",
    "            pd.notna(row['TGL_LAHIR']) and row['TGL_LAHIR'] == dob_compared and \n",
    "            pd.notna(row['cleaned_TEMPAT_LAHIR']) and row['cleaned_TEMPAT_LAHIR'] == tempat_compared and \n",
    "            pd.notna(row['cleaned_NAMA_IBU_KANDUNG']) and jaro_winkler_match(row['cleaned_NAMA_IBU_KANDUNG'], mother_name_compared)  # Rule 1\n",
    "        ):\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'Y'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = 'RULE 1'\n",
    "\n",
    "        elif (\n",
    "            name_sim and \n",
    "            pd.notna(row['cleaned_no_ktp']) and row['cleaned_no_ktp'] == ktp_kitas_compared  # Rule 2\n",
    "        ):\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'Y'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = 'RULE 2'\n",
    "\n",
    "        elif (\n",
    "            name_sim and \n",
    "            pd.notna(row['cleaned_no_npwp']) and row['cleaned_no_npwp'] == npwp_compared  # Rule 3\n",
    "        ):\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'Y'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = 'RULE 3'\n",
    "\n",
    "        elif (\n",
    "            jaro_winkler_match(row['cleaned_name'], name_compared, threshold=0.95) and \n",
    "            pd.notna(row['cleaned_alamat']) and jaro_winkler_match(row['cleaned_alamat'], address_compared) and  # Rule 4\n",
    "            pd.notna(row['cleaned_NAMA_IBU_KANDUNG']) and jaro_winkler_match(row['cleaned_NAMA_IBU_KANDUNG'], mother_name_compared)  \n",
    "        ):\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'Y'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = 'RULE 4' \n",
    "\n",
    "        elif (\n",
    "            pd.notna(row['TGL_LAHIR']) and row['TGL_LAHIR'] == dob_compared and \n",
    "            pd.notna(row['cleaned_no_ktp']) and row['cleaned_no_ktp'] == ktp_kitas_compared  # Rule 5\n",
    "        ):\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'Y'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = 'RULE 5'  \n",
    "        \n",
    "        elif (\n",
    "            jaro_winkler_match(row['cleaned_name'], name_compared, threshold=0.95) and \n",
    "            pd.notna(row['cleaned_alamat']) and jaro_winkler_match(row['cleaned_alamat'], address_compared) and\n",
    "            pd.notna(row['TGL_LAHIR']) and row['TGL_LAHIR'] == dob_compared and \n",
    "            pd.notna(row['cleaned_TEMPAT_LAHIR']) and row['cleaned_TEMPAT_LAHIR'] == tempat_compared # Rule 6\n",
    "        ):\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'Y'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = 'RULE 6'  \n",
    "\n",
    "        else:\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'N'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = None # No match, no rule number\n",
    "            \n",
    "    filtered_result_df = filtered_result_df[filtered_result_df['flag_SID'] == 'Y'].reset_index(drop=True)\n",
    "    \n",
    "    if filtered_result_df.empty:\n",
    "        row_compared_df = pd.DataFrame([row_compared])  \n",
    "        row_compared_df['flag_SID'] = 'Y'                \n",
    "        filtered_result_df = pd.concat([filtered_result_df, row_compared_df], ignore_index=True)\n",
    "\n",
    "    check_sid_exist = False\n",
    "    if not filtered_result_df['SID'].isnull().all():\n",
    "        check_sid_exist = True\n",
    "        sid_value = filtered_result_df['SID'].dropna().iloc[0]\n",
    "        break\n",
    "\n",
    "    # If no existing SID is found, generate a new one\n",
    "    if not check_sid_exist:\n",
    "        filtered_result_df = filtered_result_df.sort_values(by='DT_GOLIVE_VALID').reset_index(drop=True)\n",
    "        \n",
    "        kode_cabang = str(filtered_result_df.loc[0, 'CD_SP'])  \n",
    "        \n",
    "        cursor.execute(f\"SELECT COUNT FROM sp_count WHERE CD_SP = ({kode_cabang})\")\n",
    "        last_sequence = cursor.fetchone()\n",
    "        \n",
    "        sid_value = f\"{kode_cabang}{(int(last_sequence['COUNT']) + 1):07d}\"\n",
    "        filtered_result_df['SID'] = sid_value\n",
    "          \n",
    "print(sid_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8875d6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    RULE 6\n",
       "Name: rule_num, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_result_df['rule_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf629f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id            NO_AGGR  NAME_GOLIVE flag_PC NAMA_IBU_KANDUNG SEX  \\\n",
      "0   1  10822567375494397  EDY PRIYONO       P          SUDARMI   M   \n",
      "\n",
      "    TGL_LAHIR TEMPAT_LAHIR DT_GOLIVE_VALID   CD_SP  ...    cleaned_no_ktp  \\\n",
      "0  1967-10-01     SEMARANG      2025-05-23  100103  ...  3374140110670015   \n",
      "\n",
      "  cleaned_no_npwp cleaned_alamat cleaned_name_cob cleaned_no_ktp_cob  \\\n",
      "0                         SODONG                                       \n",
      "\n",
      "  cleaned_alamat_cob            SID SID_COBORR flag_SID rule_num  \n",
      "0                     1001030000001       None        N     None  \n",
      "\n",
      "[1 rows x 31 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1001030000002'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in df_test.iterrows():\n",
    "    if not monre_dict:\n",
    "        kode_cabang = row['CD_SP']\n",
    "        \n",
    "        cursor.execute(f\"SELECT COUNT FROM sp_count WHERE CD_SP = ({kode_cabang})\")\n",
    "        last_sequence = cursor.fetchone()\n",
    "        \n",
    "        sid_value = f\"{kode_cabang}{(int(last_sequence['COUNT']) + 1):07d}\"\n",
    "        \n",
    "        break\n",
    "    \n",
    "    row_compared = row\n",
    "    matched_dfs = []\n",
    "    results_list = add_new_name_to_results_dict(row['cleaned_name'])\n",
    "    all_indices = set()\n",
    "    for name in results_list:\n",
    "        if name in monre_dict:\n",
    "            indices = monre_dict[name]\n",
    "            all_indices.update(map(int, monre_dict[name]))\n",
    "            id_list = ','.join(map(str, all_indices))\n",
    "            cursor.execute(f\"SELECT * FROM credit_cust WHERE id IN ({id_list})\")\n",
    "            matched_dfs = cursor.fetchall()\n",
    "            matched_dfs = pd.DataFrame(matched_dfs)\n",
    "    \n",
    "    if len(matched_dfs) == 0:\n",
    "        kode_cabang = row['CD_SP']\n",
    "        \n",
    "        cursor.execute(f\"SELECT COUNT FROM sp_count WHERE CD_SP = ({kode_cabang})\")\n",
    "        last_sequence = cursor.fetchone()\n",
    "        \n",
    "        sid_value = f\"{kode_cabang}{(int(last_sequence['COUNT']) + 1):07d}\"\n",
    "        \n",
    "        break\n",
    "    else:\n",
    "        result_df_nodup = matched_dfs.drop_duplicates(subset='NO_AGGR').reset_index(drop=True)\n",
    "    \n",
    "        \n",
    "    name_compared = row['cleaned_name']\n",
    "    dob_compared = row['TGL_LAHIR']\n",
    "    tempat_compared = row['cleaned_TEMPAT_LAHIR']\n",
    "    ktp_kitas_compared = row['cleaned_no_ktp']\n",
    "    mother_name_compared = row['cleaned_NAMA_IBU_KANDUNG'] \n",
    "    npwp_compared = row['cleaned_no_npwp']\n",
    "    address_compared = row['cleaned_alamat']\n",
    "\n",
    "    # Filter result_df based on matching criteria\n",
    "    filtered_result_df = result_df_nodup[\n",
    "        ((pd.notna(result_df_nodup['TGL_LAHIR']) & pd.notna(dob_compared) & \n",
    "        (result_df_nodup['TGL_LAHIR'] == dob_compared)) |\n",
    "        (pd.notna(result_df_nodup['cleaned_no_ktp']) & pd.notna(ktp_kitas_compared) & \n",
    "        (result_df_nodup['cleaned_no_ktp'] == ktp_kitas_compared)) |\n",
    "        (pd.notna(result_df_nodup['cleaned_NAMA_IBU_KANDUNG']) & pd.notna(mother_name_compared) & \n",
    "        (result_df_nodup['cleaned_NAMA_IBU_KANDUNG'] == mother_name_compared)) |\n",
    "        (pd.notna(result_df_nodup['cleaned_no_npwp']) & pd.notna(npwp_compared) & \n",
    "        (result_df_nodup['cleaned_no_npwp'] == npwp_compared))\n",
    "    )]\n",
    "\n",
    "    filtered_result_df = filtered_result_df.copy()\n",
    "    filtered_result_df['flag_SID'] = 'N'  \n",
    "    filtered_result_df['rule_num'] = None\n",
    "    for index, row in filtered_result_df.iterrows():\n",
    "        name_sim = jaro_winkler_match(row['cleaned_name'], name_compared)\n",
    "        \n",
    "        if (\n",
    "            name_sim and \n",
    "            pd.notna(row['TGL_LAHIR']) and row['TGL_LAHIR'] == dob_compared and \n",
    "            pd.notna(row['cleaned_TEMPAT_LAHIR']) and row['cleaned_TEMPAT_LAHIR'] == tempat_compared and \n",
    "            pd.notna(row['cleaned_NAMA_IBU_KANDUNG']) and jaro_winkler_match(row['cleaned_NAMA_IBU_KANDUNG'], mother_name_compared)  # Rule 1\n",
    "        ):\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'Y'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = 'RULE 1'\n",
    "\n",
    "        elif (\n",
    "            name_sim and \n",
    "            pd.notna(row['cleaned_no_ktp']) and row['cleaned_no_ktp'] == ktp_kitas_compared  # Rule 2\n",
    "        ):\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'Y'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = 'RULE 2'\n",
    "\n",
    "        elif (\n",
    "            name_sim and \n",
    "            pd.notna(row['cleaned_no_npwp']) and row['cleaned_no_npwp'] == npwp_compared  # Rule 3\n",
    "        ):\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'Y'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = 'RULE 3'\n",
    "\n",
    "        elif (\n",
    "            jaro_winkler_match(row['cleaned_name'], name_compared, threshold=0.95) and \n",
    "            pd.notna(row['cleaned_alamat']) and jaro_winkler_match(row['cleaned_alamat'], address_compared) and  # Rule 4\n",
    "            pd.notna(row['cleaned_NAMA_IBU_KANDUNG']) and jaro_winkler_match(row['cleaned_NAMA_IBU_KANDUNG'], mother_name_compared)  \n",
    "        ):\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'Y'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = 'RULE 4' \n",
    "\n",
    "        elif (\n",
    "            pd.notna(row['TGL_LAHIR']) and row['TGL_LAHIR'] == dob_compared and \n",
    "            pd.notna(row['cleaned_no_ktp']) and row['cleaned_no_ktp'] == ktp_kitas_compared  # Rule 5\n",
    "        ):\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'Y'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = 'RULE 5'  \n",
    "        \n",
    "        elif (\n",
    "            jaro_winkler_match(row['cleaned_name'], name_compared, threshold=0.95) and \n",
    "            pd.notna(row['cleaned_alamat']) and jaro_winkler_match(row['cleaned_alamat'], address_compared) and\n",
    "            pd.notna(row['TGL_LAHIR']) and row['TGL_LAHIR'] == dob_compared and \n",
    "            pd.notna(row['cleaned_TEMPAT_LAHIR']) and row['cleaned_TEMPAT_LAHIR'] == tempat_compared # Rule 6\n",
    "        ):\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'Y'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = 'RULE 6'  \n",
    "\n",
    "        else:\n",
    "            filtered_result_df.loc[index, 'flag_SID'] = 'N'\n",
    "            filtered_result_df.loc[index, 'rule_num'] = None # No match, no rule number\n",
    "    print(filtered_result_df)\n",
    "    filtered_result_df = filtered_result_df[filtered_result_df['flag_SID'] == 'Y'].reset_index(drop=True)\n",
    "\n",
    "    if filtered_result_df.empty:\n",
    "        row_compared_df = pd.DataFrame([row_compared])  \n",
    "        row_compared_df['flag_SID'] = 'Y'                \n",
    "        filtered_result_df = pd.concat([filtered_result_df, row_compared_df], ignore_index=True)\n",
    "\n",
    "    check_sid_exist = False\n",
    "    if not filtered_result_df['SID'].isnull().all():\n",
    "        check_sid_exist = True\n",
    "        sid_value = filtered_result_df['SID'].dropna().iloc[0]\n",
    "        break\n",
    "\n",
    "    # If no existing SID is found, generate a new one\n",
    "    if not check_sid_exist:\n",
    "        filtered_result_df = filtered_result_df.sort_values(by='DT_GOLIVE_VALID').reset_index(drop=True)\n",
    "        \n",
    "        kode_cabang = str(filtered_result_df.loc[0, 'CD_SP']) \n",
    "        cursor.execute(\"SELECT COUNT FROM sp_count WHERE CD_SP = %s\", (kode_cabang,))\n",
    "        last_sequence = cursor.fetchone()\n",
    "        \n",
    "        sid_value = f\"{kode_cabang}{(int(last_sequence['COUNT']) + 1):07d}\"\n",
    "        \n",
    "        filtered_result_df['SID'] = sid_value\n",
    "        \n",
    "sid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ace16a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.get_jaro_distance(\"EDI PRIYONO\", \"EDY PRIYONO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7bf876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EDI PRIYOTNO'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83bcae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5005780000001\n"
     ]
    }
   ],
   "source": [
    "# SID COBORR\n",
    "for index, row in df_test.iterrows():\n",
    "    name_compared = row['cleaned_name_cob']\n",
    "    name_borr_compared = row['cleaned_name']\n",
    "    dob_compared = row['TGL_LAHIR_COBORR']\n",
    "    ktp_kitas_compared = row['cleaned_no_ktp_cob']\n",
    "    address_compared = row['cleaned_alamat_cob']\n",
    "    sid_compared = sid_value\n",
    "\n",
    "    if pd.notna(row['cleaned_name_cob']) and row['cleaned_name_cob'] != '' and row['cleaned_name_cob'] != 'nan':\n",
    "        row_compared = row\n",
    "        matched_dfs = []\n",
    "        all_indices_coborr = set()\n",
    "        id_list = None\n",
    "        results_list = add_new_name_to_results_dict(row['cleaned_name_cob'])\n",
    "        \n",
    "        for name in results_list:\n",
    "            if name in monre_dict:\n",
    "                indices = monre_dict[name]\n",
    "                all_indices_coborr.update(map(int, monre_dict[name]))\n",
    "                id_list = ','.join(map(str, all_indices_coborr))\n",
    "                cursor.execute(f\"SELECT * FROM credit_cust WHERE id IN ({id_list})\")\n",
    "                rows_sql = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description]\n",
    "                matched_df = pd.DataFrame(rows_sql, columns=columns)\n",
    "                matched_dfs.append(matched_df)\n",
    "\n",
    "        if len(matched_dfs) > 0:\n",
    "            combined_df = pd.concat(matched_dfs, ignore_index=True)\n",
    "            mask = (\n",
    "                (combined_df['TGL_LAHIR'] == dob_compared) |\n",
    "                (combined_df['cleaned_no_ktp'] == ktp_kitas_compared)\n",
    "            )\n",
    "            filtered_result_df = combined_df[mask].copy()\n",
    "            filtered_result_df['flag'] = None \n",
    "            \n",
    "            for index, row in filtered_result_df.iterrows():\n",
    "                name_sim = jaro_winkler_match(row['cleaned_name'], name_compared)\n",
    "                if (\n",
    "                    name_sim and \n",
    "                    pd.notna(row['cleaned_no_ktp']) and pd.notna(ktp_kitas_compared) \n",
    "                    and row['cleaned_no_ktp'] == ktp_kitas_compared  \n",
    "                ):\n",
    "                    filtered_result_df.loc[index, 'flag'] = 'Y'\n",
    "                    filtered_result_df.loc[index, 'rule_num'] = 'RULE 1'\n",
    "                elif (\n",
    "                    pd.notna(row['TGL_LAHIR']) and pd.notna(dob_compared) and row['TGL_LAHIR'] == dob_compared and \n",
    "                    pd.notna(row['cleaned_no_ktp']) and pd.notna(ktp_kitas_compared) and row['cleaned_no_ktp'] == ktp_kitas_compared  # Rule 5\n",
    "                ):\n",
    "                    filtered_result_df.loc[index, 'flag'] = 'Y'\n",
    "                    filtered_result_df.loc[index, 'rule_num'] = 'RULE 2'  \n",
    "                else:\n",
    "                    filtered_result_df.loc[index, 'flag'] = 'N'\n",
    "                    filtered_result_df.loc[index, 'rule_num'] = None \n",
    "\n",
    "            filtered_result_df = filtered_result_df[filtered_result_df['flag'] == 'Y']\n",
    "            if len(filtered_result_df) == 0 :\n",
    "                print(\"1\")\n",
    "                sid_cobor_value = None\n",
    "            else:\n",
    "                if filtered_result_df['SID'].nunique() > 1:\n",
    "                    print('Coborr dimiripkan dengan 2 SID berbeda yaitu:')\n",
    "                    print(filtered_result_df['SID'].unique())\n",
    "                else:\n",
    "                    print(\"2\")\n",
    "                    sid_cobor_value = filtered_result_df['SID'].iloc[0]\n",
    "        else:\n",
    "            print(\"3\")\n",
    "            sid_cobor_value = None\n",
    "    else:\n",
    "        print(\"4\")\n",
    "        sid_cobor_value = None\n",
    "print(sid_cobor_value)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4f75903",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM mst_sid_borr_coborr\")\n",
    "mst_sid_borr_coborr = cursor.fetchall()\n",
    "mst_sid_borr_coborr = pd.DataFrame(mst_sid_borr_coborr)\n",
    "\n",
    "if len(mst_sid_borr_coborr)==0:\n",
    "    mst_sid_borr_coborr = pd.DataFrame(columns=['SID_BORR','SID_COBORR','GID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7bee294",
   "metadata": {},
   "outputs": [],
   "source": [
    "exists = False\n",
    "\n",
    "if pd.notna(sid_value) and pd.notna(sid_cobor_value):\n",
    "    if not mst_sid_borr_coborr[\n",
    "        (mst_sid_borr_coborr['SID_BORR'] == sid_value) &\n",
    "        (mst_sid_borr_coborr['SID_COBORR'] == sid_cobor_value)\n",
    "    ].empty:\n",
    "        exists = True\n",
    "\n",
    "elif pd.isna(sid_cobor_value):\n",
    "    if not mst_sid_borr_coborr[\n",
    "        mst_sid_borr_coborr['SID_BORR'] == sid_value\n",
    "    ].empty:\n",
    "        exists = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2094393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SID_BORR     SID_COBORR             GID\n",
      "0  1001030000001           None  G1001030000001\n",
      "1  1001940000001           None  G1001940000001\n",
      "2  5005780000001           None  G1001940000001\n",
      "3  1001940000001  5005780000001  G1001940000001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "added_to_mst_gid = False\n",
    "\n",
    "# Append only if the pair does not exist\n",
    "if not exists:\n",
    "    new_row = pd.DataFrame([{\n",
    "        'SID_BORR': sid_value,\n",
    "        'SID_COBORR': sid_cobor_value,\n",
    "        'GID': None\n",
    "    }])\n",
    "    mst_sid_borr_coborr = pd.concat([mst_sid_borr_coborr, new_row], ignore_index=True)\n",
    "    added_to_mst_gid = True\n",
    "    \n",
    "if added_to_mst_gid:\n",
    "    G = nx.Graph()\n",
    "    for _, row in mst_sid_borr_coborr.iterrows():\n",
    "        if pd.notna(row[\"SID_COBORR\"]):  # Jika ada pasangan\n",
    "            G.add_edge(row[\"SID_BORR\"], row[\"SID_COBORR\"])\n",
    "        else:  # Jika tidak ada pasangan\n",
    "            G.add_node(row[\"SID_BORR\"])\n",
    "\n",
    "    # Perbarui GID tanpa mengubah yang lama\n",
    "    components = list(nx.connected_components(G))\n",
    "    gid_mapping = {node: f\"G{str(int(min(comp)))}\" for comp in components for node in comp}\n",
    "    mst_sid_borr_coborr[\"GID\"] = mst_sid_borr_coborr[\"SID_BORR\"].map(gid_mapping)\n",
    "    print(mst_sid_borr_coborr)\n",
    "     # Drop and recreate the SQL table\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS mst_sid_borr_coborr\")\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE mst_sid_borr_coborr (\n",
    "            SID_BORR VARCHAR(13),\n",
    "            SID_COBORR VARCHAR(13),\n",
    "            GID VARCHAR(14)\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "    # Insert data into SQL\n",
    "    for _, row in mst_sid_borr_coborr.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO mst_sid_borr_coborr (SID_BORR, SID_COBORR, GID)\n",
    "        VALUES (%s, %s, %s)\n",
    "    \"\"\", (row[\"SID_BORR\"], row[\"SID_COBORR\"], row[\"GID\"]))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c472f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    G1001030000001\n",
       "Name: GID, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if sid_cobor_value == None:\n",
    "    gid_value = mst_sid_borr_coborr[mst_sid_borr_coborr['SID_BORR']==sid_value]['GID']\n",
    "else:\n",
    "    gid_value = mst_sid_borr_coborr[(mst_sid_borr_coborr['SID_BORR']==sid_value)&(mst_sid_borr_coborr['SID_COBORR']==sid_cobor_value)]['GID']\n",
    "gid_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
